{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KernelPyLogit using KFold Cross-validation\n",
    "\n",
    "The purpose of this Jupyter notebook is to demonstrate how the KFold Cross-val function can be used to estimate a Random Utility Model (RUM) and a Kernel Logistic Regression (KLR) model. It is assumed that the user has already read the 'Main PyKernelLogit Example' notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset selected for this example is the 'Mode' dataset from the 'mlogit' package for R programming language (https://cran.r-project.org/web/packages/mlogit/mlogit.pdf). This dataset was elaborated by a project team in 'Discrete choice methods with simulation' (Train, 2003) and contains data about the mode choice of $453$ commuters. Each commuter has four available travel modes for their trips to work in a choice set $C=\\{ \\hbox{}bus, car, carpool, rail  \\}$. The time and cost of travel for each mode were determined for each commuter. The attributes of the alternative $i \\in C$ for the commuter $n$  are $x_{in}=(x_{in,cost}, x_{in,time})$ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the different packages that will be used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict    # For recording the model specification \n",
    "\n",
    "import pandas as pd                    # For file input/output\n",
    "import numpy as np                     # For vectorized math operations\n",
    "\n",
    "import PyKernelLogit as pkl            # For the estimation of the MNL and KLR models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing the data\n",
    "\n",
    "### 1.1. Load the data\n",
    "The first step to estimate a model using PyKernelLogit is loading the dataset using a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>choice</td>\n",
       "      <td>car</td>\n",
       "      <td>rail</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cost.car</td>\n",
       "      <td>1.50701</td>\n",
       "      <td>6.057</td>\n",
       "      <td>5.79468</td>\n",
       "      <td>1.86914</td>\n",
       "      <td>2.49895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cost.carpool</td>\n",
       "      <td>2.33561</td>\n",
       "      <td>2.89692</td>\n",
       "      <td>2.13745</td>\n",
       "      <td>2.57243</td>\n",
       "      <td>1.72201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cost.bus</td>\n",
       "      <td>1.80051</td>\n",
       "      <td>2.23713</td>\n",
       "      <td>2.57638</td>\n",
       "      <td>1.90352</td>\n",
       "      <td>2.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cost.rail</td>\n",
       "      <td>2.35892</td>\n",
       "      <td>1.85545</td>\n",
       "      <td>2.74748</td>\n",
       "      <td>2.26828</td>\n",
       "      <td>2.97387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time.car</td>\n",
       "      <td>18.5032</td>\n",
       "      <td>31.3111</td>\n",
       "      <td>22.5474</td>\n",
       "      <td>26.0903</td>\n",
       "      <td>4.69914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time.carpool</td>\n",
       "      <td>26.3382</td>\n",
       "      <td>34.257</td>\n",
       "      <td>23.2552</td>\n",
       "      <td>29.896</td>\n",
       "      <td>12.4141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time.bus</td>\n",
       "      <td>20.8678</td>\n",
       "      <td>67.1819</td>\n",
       "      <td>63.3091</td>\n",
       "      <td>19.7527</td>\n",
       "      <td>43.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time.rail</td>\n",
       "      <td>30.0335</td>\n",
       "      <td>60.2931</td>\n",
       "      <td>49.1716</td>\n",
       "      <td>13.4727</td>\n",
       "      <td>39.7433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1        2        3        4\n",
       "choice            car     rail      car      car      car\n",
       "cost.car      1.50701    6.057  5.79468  1.86914  2.49895\n",
       "cost.carpool  2.33561  2.89692  2.13745  2.57243  1.72201\n",
       "cost.bus      1.80051  2.23713  2.57638  1.90352    2.686\n",
       "cost.rail     2.35892  1.85545  2.74748  2.26828  2.97387\n",
       "time.car      18.5032  31.3111  22.5474  26.0903  4.69914\n",
       "time.carpool  26.3382   34.257  23.2552   29.896  12.4141\n",
       "time.bus      20.8678  67.1819  63.3091  19.7527   43.092\n",
       "time.rail     30.0335  60.2931  49.1716  13.4727  39.7433"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Mode dataset from a .csv file. Nota that all the elements are delimited by a ',' character.\n",
    "mode_choice = pd.read_csv(\"../data/ModeChoice.csv\", sep=',')\n",
    "\n",
    "# Show the first 5 rows of the data\n",
    "mode_choice.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Convert the dataset to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['choice', 'cost.car', 'cost.carpool', 'cost.bus', 'cost.rail',\n",
       "       'time.car', 'time.carpool', 'time.bus', 'time.rail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the columns of the Mode dataset\n",
    "mode_choice.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert choice from categorical variable to numeric one\n",
    "mode_choice['choice'] = mode_choice['choice'].map({'car' : 1, 'carpool' : 2 , 'bus' : 3, 'rail' : 4})\n",
    "\n",
    "# Create the list of individual specific variables\n",
    "ind_variables = [] # There are no indivicual specific variables in this dataset\n",
    "\n",
    "# Variables that vary across some or all alternatives, for a given individual\n",
    "alt_varying_variables = {u'cost': dict([(1, 'cost.car'),\n",
    "                                        (2, 'cost.carpool'),\n",
    "                                        (3, 'cost.bus'),\n",
    "                                        (4, 'cost.rail')]),\n",
    "                         u'time': dict([(1, 'time.car'),\n",
    "                                        (2, 'time.carpool'),\n",
    "                                        (3, 'time.bus'),\n",
    "                                        (4, 'time.rail')])\n",
    "                        }\n",
    "\n",
    "### Specify the availability variables\n",
    "# Note that the keys of the dictionary are the alternative id's.\n",
    "# The values are the columns denoting the availability for the\n",
    "# given mode in the dataset. If the dataset does not contains any\n",
    "# availability columns (such as in the Mode dataset), then the \n",
    "# keyword 'available_for_all' can be used to specify that an alternative\n",
    "# is availables for all individuals.\n",
    "availability_variables = {1: 'available_for_all',\n",
    "                          2: 'available_for_all', \n",
    "                          3: 'available_for_all',\n",
    "                          4: 'available_for_all'}\n",
    "\n",
    "### Determine the columns for: alternative ids, the observation ids and the choice\n",
    "\n",
    "# The 'custom_alt_id' is the name of a column to be created in the long format data\n",
    "# It will identify the alternative associated with each row.\n",
    "custom_alt_id = \"mode_id\"\n",
    "\n",
    "# Create a custom id column. Note the +1 ensures the id's start at one.\n",
    "obs_id_column = \"custom_id\"\n",
    "mode_choice[obs_id_column] = np.arange(mode_choice.shape[0], dtype=int) + 1\n",
    "\n",
    "# Create a variable recording the choice column\n",
    "choice_column = \"choice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the conversion to long format\n",
    "long_mode_choice = pkl.convert_wide_to_long(mode_choice, \n",
    "                                           ind_variables, \n",
    "                                           alt_varying_variables, \n",
    "                                           availability_variables, \n",
    "                                           obs_id_column, \n",
    "                                           choice_column,\n",
    "                                           new_alt_id_name=custom_alt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>custom_id</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mode_id</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>choice</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cost</td>\n",
       "      <td>1.50701</td>\n",
       "      <td>2.335612</td>\n",
       "      <td>1.800512</td>\n",
       "      <td>2.358920</td>\n",
       "      <td>6.056998</td>\n",
       "      <td>2.896919</td>\n",
       "      <td>2.237128</td>\n",
       "      <td>1.855451</td>\n",
       "      <td>5.794677</td>\n",
       "      <td>2.137454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time</td>\n",
       "      <td>18.50320</td>\n",
       "      <td>26.338233</td>\n",
       "      <td>20.867794</td>\n",
       "      <td>30.033469</td>\n",
       "      <td>31.311107</td>\n",
       "      <td>34.256956</td>\n",
       "      <td>67.181889</td>\n",
       "      <td>60.293126</td>\n",
       "      <td>22.547429</td>\n",
       "      <td>23.255171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1          2          3          4          5  \\\n",
       "custom_id   1.00000   1.000000   1.000000   1.000000   2.000000   2.000000   \n",
       "mode_id     1.00000   2.000000   3.000000   4.000000   1.000000   2.000000   \n",
       "choice      1.00000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "cost        1.50701   2.335612   1.800512   2.358920   6.056998   2.896919   \n",
       "time       18.50320  26.338233  20.867794  30.033469  31.311107  34.256956   \n",
       "\n",
       "                   6          7          8          9  \n",
       "custom_id   2.000000   2.000000   3.000000   3.000000  \n",
       "mode_id     3.000000   4.000000   1.000000   2.000000  \n",
       "choice      0.000000   1.000000   1.000000   0.000000  \n",
       "cost        2.237128   1.855451   5.794677   2.137454  \n",
       "time       67.181889  60.293126  22.547429  23.255171  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the resulting long format dataframe\n",
    "long_mode_choice.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimation of a RUM using KFold Cross-validation\n",
    "\n",
    "In Machine Learning (ML) it is recommended to perform a cross-validation, which is a resampling procedure used to estimate the skill of ML models on a limited data sample. The most commonly cross-validation technique is K-fold cross-validation. This procedure has a single parameter called $K$ which contains the number of subsets, called folds, in which a given data sample are divided. If $K = 10$, for instance, then the procedure is named 10-fold cross-validation. Then, a test subset is generated picking a different fold for every iteration and the other $K-1$ folds are used as the training subset. Then, the model is estimated using this training subset and tested on the test subset for each of the $K$ iterations. The final results are commonly computed as the average of the individual results for each iteration.\n",
    "\n",
    "PyKernelLogit provides a function named KFold_cross_val which implements KFold Cross-validation. This function takes the following input arguments:\n",
    "* long_data. The pandas dataframe in long format which is going to be used by the cross-validator.\n",
    "\n",
    "* obs_id_col. The column from the wide dataset that contains the ID of each observation.\n",
    "\n",
    "* n_splits. The number of folds ($K$).\n",
    "\n",
    "* shuffle. A boolean parameter that determines whether or not the data must be shuffled before splitting it into batches.\n",
    "\n",
    "* random_state. An integer value which is used as the seed for the random number generator.\n",
    "\n",
    "The KFold_cross_val function uses a Python yield statement that creates a generator function which returns an iterator known as a generator iterator. The body of the generator function is executed by calling the generator's next() method repeatedly until it raises an exception. The main advantage of the yield statement is that it simplifies the application of the K-fold cross-validation, because the KFold_cross_val function can be called inside a for loop. Then, at each iteration of the loop, the corresponding training and test set are computed by this generator iterator.\n",
    "\n",
    "The next code estimates and evaluates a RUM using 10-Fold Cross-validation. The model specification used is the same as in the 'Main PyKernelLogit Example' notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty basic_specification and basic_names ordered dictionary\n",
    "basic_specification = OrderedDict()\n",
    "basic_names = OrderedDict()\n",
    "\n",
    "# Model specification\n",
    "basic_specification[\"intercept\"] = [2, 3, 4]\n",
    "basic_names[\"intercept\"] = ['ASC CarPool',\n",
    "                            'ASC Bus',\n",
    "                            'ASC Rail']\n",
    "\n",
    "basic_specification[\"cost\"] = [[1, 2, 3, 4]]\n",
    "basic_names[\"cost\"] = ['Travel cost (dollars)']\n",
    "\n",
    "basic_specification[\"time\"] = [[1, 2, 3, 4]]\n",
    "basic_names[\"time\"] = ['Travel time (minutes)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Set 1 ---\n",
      "Log-likelihood at zero: -564.2218\n",
      "Initial Log-likelihood: -564.2218\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -319.1546\n",
      "Rho squared: 0.434345\n",
      "Precision: 0.739130, Recall: 0.739130, FScore: 0.739130\n",
      "--- Set 2 ---\n",
      "Log-likelihood at zero: -564.2218\n",
      "Initial Log-likelihood: -564.2218\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -316.4052\n",
      "Rho squared: 0.439218\n",
      "Precision: 0.608696, Recall: 0.608696, FScore: 0.608696\n",
      "--- Set 3 ---\n",
      "Log-likelihood at zero: -564.2218\n",
      "Initial Log-likelihood: -564.2218\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -322.1470\n",
      "Rho squared: 0.429042\n",
      "Precision: 0.695652, Recall: 0.695652, FScore: 0.695652\n",
      "--- Set 4 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -322.0688\n",
      "Rho squared: 0.430580\n",
      "Precision: 0.688889, Recall: 0.688889, FScore: 0.688889\n",
      "--- Set 5 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -326.2585\n",
      "Rho squared: 0.423172\n",
      "Precision: 0.800000, Recall: 0.800000, FScore: 0.800000\n",
      "--- Set 6 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -321.6866\n",
      "Rho squared: 0.431255\n",
      "Precision: 0.666667, Recall: 0.666667, FScore: 0.666667\n",
      "--- Set 7 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -309.6878\n",
      "Rho squared: 0.452469\n",
      "Precision: 0.577778, Recall: 0.577778, FScore: 0.577778\n",
      "--- Set 8 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -312.4415\n",
      "Rho squared: 0.447601\n",
      "Precision: 0.533333, Recall: 0.533333, FScore: 0.533333\n",
      "--- Set 9 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.04 seconds.\n",
      "Final log-likelihood: -317.5469\n",
      "Rho squared: 0.438574\n",
      "Precision: 0.622222, Recall: 0.622222, FScore: 0.622222\n",
      "--- Set 10 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.01 seconds.\n",
      "Final log-likelihood: -319.7691\n",
      "Rho squared: 0.434645\n",
      "Precision: 0.711111, Recall: 0.711111, FScore: 0.711111\n",
      "\n",
      " --------------------- Final Results ---------------------\n",
      "Precision: 0.664348, Recall: 0.664348, FScore: 0.664348\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "fscore = 0\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "for train_set, test_set in pkl.KFold_cross_val(long_mode_choice,\n",
    "                                               obs_id_column,\n",
    "                                               n_splits,\n",
    "                                               shuffle=False,\n",
    "                                               random_state=1):\n",
    "    \n",
    "    fold += 1\n",
    "    print(\"--- Set %d ---\" % fold)\n",
    "    \n",
    "    # Estimate the multinomial logit model (MNL)\n",
    "    linear_model = pkl.create_choice_model(data=train_set,\n",
    "                                            alt_id_col=custom_alt_id,\n",
    "                                            obs_id_col=obs_id_column,\n",
    "                                            choice_col=choice_column,\n",
    "                                            specification=basic_specification,\n",
    "                                            model_type=\"MNL\",\n",
    "                                            names=basic_names)\n",
    "    \n",
    "    # Specify the initial values and method for the optimization.\n",
    "    linear_model.fit_mle(np.zeros(5))\n",
    "    print(\"Rho squared: %f\" % linear_model.rho_squared)\n",
    "    \n",
    "    (precision_fold, recall_fold, fscore_fold) = linear_model.precision_recall_fscore(test_set, \"micro\", beta = 1)\n",
    "\n",
    "    print(\"Precision: %f, Recall: %f, FScore: %f\" % (precision_fold, recall_fold, fscore_fold))\n",
    "    \n",
    "    precision += precision_fold\n",
    "    recall += recall_fold\n",
    "    fscore += fscore_fold\n",
    "    \n",
    "print(\"\\n --------------------- Final Results ---------------------\")\n",
    "print(\"Precision: %f, Recall: %f, FScore: %f\" % (precision/n_splits, recall/n_splits, fscore/n_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimation of a KLR model using KFold Cross-validation\n",
    "\n",
    "Now, a KLR model is evaluated using 10-Fold Cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to used per alternative\n",
    "variables = {1: ['cost', 'time'],\n",
    "             2: ['cost', 'time'],\n",
    "             3: ['cost', 'time'],\n",
    "             4: ['cost', 'time']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings generated when fitting the model because the covariance matrix is singular.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Set 1 ---\n",
      "Log-likelihood at zero: -564.2218\n",
      "Initial Log-likelihood: -564.2218\n",
      "Estimation Time for Point Estimation: 0.06 seconds.\n",
      "Final log-likelihood: -346.7395\n",
      "Precision: 0.673913, Recall: 0.673913, FScore: 0.673913\n",
      "--- Set 2 ---\n",
      "Log-likelihood at zero: -564.2218\n",
      "Initial Log-likelihood: -564.2218\n",
      "Estimation Time for Point Estimation: 0.06 seconds.\n",
      "Final log-likelihood: -343.2334\n",
      "Precision: 0.586957, Recall: 0.586957, FScore: 0.586957\n",
      "--- Set 3 ---\n",
      "Log-likelihood at zero: -564.2218\n",
      "Initial Log-likelihood: -564.2218\n",
      "Estimation Time for Point Estimation: 0.05 seconds.\n",
      "Final log-likelihood: -348.7580\n",
      "Precision: 0.760870, Recall: 0.760870, FScore: 0.760870\n",
      "--- Set 4 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.07 seconds.\n",
      "Final log-likelihood: -350.5128\n",
      "Precision: 0.733333, Recall: 0.733333, FScore: 0.733333\n",
      "--- Set 5 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.09 seconds.\n",
      "Final log-likelihood: -354.9706\n",
      "Precision: 0.777778, Recall: 0.777778, FScore: 0.777778\n",
      "--- Set 6 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.06 seconds.\n",
      "Final log-likelihood: -348.0038\n",
      "Precision: 0.688889, Recall: 0.688889, FScore: 0.688889\n",
      "--- Set 7 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.06 seconds.\n",
      "Final log-likelihood: -339.8173\n",
      "Precision: 0.600000, Recall: 0.600000, FScore: 0.600000\n",
      "--- Set 8 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.05 seconds.\n",
      "Final log-likelihood: -345.5869\n",
      "Precision: 0.577778, Recall: 0.577778, FScore: 0.577778\n",
      "--- Set 9 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.05 seconds.\n",
      "Final log-likelihood: -347.1406\n",
      "Precision: 0.688889, Recall: 0.688889, FScore: 0.688889\n",
      "--- Set 10 ---\n",
      "Log-likelihood at zero: -565.6081\n",
      "Initial Log-likelihood: -565.6081\n",
      "Estimation Time for Point Estimation: 0.06 seconds.\n",
      "Final log-likelihood: -345.4946\n",
      "Precision: 0.688889, Recall: 0.688889, FScore: 0.688889\n",
      "\n",
      " --------------------- Final Results ---------------------\n",
      "Precision: 0.677729, Recall: 0.677729, FScore: 0.677729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "fold = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "fscore = 0\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "for train_set, test_set in pkl.KFold_cross_val(long_mode_choice,\n",
    "                                               obs_id_column,\n",
    "                                               n_splits,\n",
    "                                               shuffle=False,\n",
    "                                               random_state=1):\n",
    "    \n",
    "    fold += 1\n",
    "    print(\"--- Set %d ---\" % fold)\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_set[['cost', 'time']])\n",
    "\n",
    "    train_set_scaled = train_set.copy()\n",
    "    train_set_scaled[['cost', 'time']] = scaler.transform(train_set[['cost', 'time']])\n",
    "\n",
    "    test_set_scaled = test_set.copy()\n",
    "    test_set_scaled[['cost', 'time']] = scaler.transform(test_set[['cost', 'time']])\n",
    "    \n",
    "    # Generate the train and test Kernel Matrices\n",
    "    K_long_format_train = pkl.long_format_with_kernel_matrix(train_set_scaled, \n",
    "                                                             custom_alt_id, \n",
    "                                                             obs_id_column, \n",
    "                                                             choice_column, \n",
    "                                                             variables, \n",
    "                                                             kernel_type = \"RBF\")\n",
    "    \n",
    "    K_long_format_test = pkl.long_format_with_kernel_matrix(test_set_scaled, \n",
    "                                                            custom_alt_id, \n",
    "                                                            obs_id_column, \n",
    "                                                            choice_column, \n",
    "                                                            variables, \n",
    "                                                            kernel_type = \"RBF\", \n",
    "                                                            Z = train_set_scaled,\n",
    "                                                            length_scale = 1)\n",
    "\n",
    "    # Define the kernel specification\n",
    "    [basic_specification, basic_names, total_vars] = pkl.define_kernel_specification(K_long_format_train, \n",
    "                                                                                     custom_alt_id,\n",
    "                                                                                     obs_id_column,\n",
    "                                                                                     specification=OrderedDict(),\n",
    "                                                                                     names=OrderedDict(),\n",
    "                                                                                     alpha_per_alternative=False,\n",
    "                                                                                     intercept=1)\n",
    "\n",
    "    \n",
    "    # Estimate the multinomial logit model (MNL)\n",
    "    kernel_model = pkl.create_choice_model(data=K_long_format_train,\n",
    "                                           alt_id_col=custom_alt_id,\n",
    "                                           obs_id_col=obs_id_column,\n",
    "                                           choice_col=choice_column,\n",
    "                                           specification=basic_specification,\n",
    "                                           model_type=\"MNL\",\n",
    "                                           names=basic_names)\n",
    "    \n",
    "    # Specify the initial values and method for the optimization.\n",
    "    kernel_model.fit_mle(np.zeros(total_vars), method=\"L-BFGS-B\", PMLE=\"RIDGE\", PMLE_lambda=4)\n",
    "    \n",
    "    (precision_fold, recall_fold, fscore_fold) = kernel_model.precision_recall_fscore(K_long_format_test, \"micro\", beta = 1)\n",
    "\n",
    "    print(\"Precision: %f, Recall: %f, FScore: %f\" % (precision_fold, recall_fold, fscore_fold))\n",
    "    \n",
    "    precision += precision_fold\n",
    "    recall += recall_fold\n",
    "    fscore += fscore_fold\n",
    "    \n",
    "print(\"\\n --------------------- Final Results ---------------------\")\n",
    "print(\"Precision: %f, Recall: %f, FScore: %f\" % (precision/n_splits, recall/n_splits, fscore/n_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Jupyter notebook\n",
    "\n",
    "This Jupyter notebook was developed by José Ángel Martín Baos on September 2019 to demonstrate the key functionalities of the PyKernelLogit Python package (https://pypi.org/project/pykernellogit/). This package is based on the PyLogit Python package (https://pypi.org/project/pylogit/) developed by Timothy Brathwaite (Timothy Brathwaite and Joan L. Walker. Asymmetric, closed-form, finite-parameter models of multinomial choice. Journal of Choice Modelling. Volume 29, December 2018.). This notebook is based on the example notebook for the PyLogit package.\n",
    "\n",
    "* José Ángel Martín Baos (https://joseangelmartinb.github.io/). Faculty of Computer Science. University of Castilla-La Mancha. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
